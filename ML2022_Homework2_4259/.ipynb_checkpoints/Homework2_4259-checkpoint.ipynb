{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60613d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author Kosmas Apostolidis \n",
    "#AM:4259\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from random import randrange\n",
    "from random import choice\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input , Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "108e872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_train_data = r'C:\\Users\\cosma\\Desktop\\EVERYTHING\\MachineLearning\\ML2022 Homework2   4259\\all_faces' #Local directory with the faces dataset\n",
    "faces_from_train_dataset = [] #A list with faces\n",
    "y_true = [] #True labels                \n",
    "label = 0   #0...49\n",
    "\n",
    "agglo_clust_accuracy_scores = []\n",
    "agglo_clust_precision   = []\n",
    "agglo_clust_recall      = []\n",
    "agglo_clust_F_measures  = []\n",
    "agglo_clust_purity_scores = []\n",
    "\n",
    "#Distance metrics used to K-Means algorithm\n",
    "distance_metrics = ['euclidean' , 'cosine'] \n",
    "\n",
    "list_accuracy_scores  = []\n",
    "list_F_measures       = []\n",
    "list_purity_scores    = []\n",
    "list_precision_scores = []\n",
    "list_recall_scores    = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c87d7e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face_from_train_dataset(list_faces,rnd_person):\n",
    "    rnd_face   = randrange(50)   #Generate random integer between 0 and 49\n",
    "    if rnd_face > len(list_faces) - 1:\n",
    "        rnd_face           = randrange(len(list_faces) - 1)   #Generate random integer between 0 and len(person_imgs) - 1\n",
    "        face               = list_faces[rnd_face] #Get the last image of tthe rnd person\n",
    "        train_colored_face = np.asarray(Image.open(dir_train_data+\"\\\\\"+str(rnd_person)+\"\\\\\"+str(face)))\n",
    "        rbg_to_grayscale   = np.mean(train_colored_face , axis = 2) #convert a color image 3D array to a grayscale 2D\n",
    "        faces_from_train_dataset.append(rbg_to_grayscale) #Append the train_img to the list\n",
    "        y_true.append(label)\n",
    "    else:\n",
    "        face                = list_faces[rnd_face] #Get the random image of the train dataset\n",
    "        train_colored_face  = np.asarray(Image.open(dir_train_data+\"\\\\\"+str(rnd_person)+\"\\\\\"+str(face)))\n",
    "        rbg_to_grayscale    = np.mean(train_colored_face , axis = 2) #convert a color image 3D array to a grayscale 2D\n",
    "        faces_from_train_dataset.append(rbg_to_grayscale) #Append the img to the list\n",
    "        y_true.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27ae5c99",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Το σύστημα δεν είναι σε θέση να εντοπίσει την καθορισμένη διαδρομή δίσκου: 'C:\\\\Users\\\\cosma\\\\Desktop\\\\EVERYTHING\\\\MachineLearning\\\\all_faces\\\\train_data\\\\1709'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12036/3352205258.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcounter\u001b[0m     \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mperson\u001b[0m      \u001b[1;33m=\u001b[0m \u001b[0mrandrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4000\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m#Generate random integer between 0 and 3999\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mlist_faces_from_train_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_train_data\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"\\\\\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperson\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mcounter\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mget_face_from_train_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_faces_from_train_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mperson\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Το σύστημα δεν είναι σε θέση να εντοπίσει την καθορισμένη διαδρομή δίσκου: 'C:\\\\Users\\\\cosma\\\\Desktop\\\\EVERYTHING\\\\MachineLearning\\\\all_faces\\\\train_data\\\\1709'"
     ]
    }
   ],
   "source": [
    "#Here i choose 10 random people from the dataset and for each one of them i choose 50 random pictures\n",
    "#Get 50 random images of 10 random people\n",
    "for i in range(10):\n",
    "    counter     = 0 \n",
    "    person      = randrange(4000)     #Generate random integer between 0 and 3999\n",
    "    list_faces_from_train_dataset = os.listdir(dir_train_data+\"\\\\\"+str(person)) \n",
    "    while counter < 50:\n",
    "        get_face_from_train_dataset(list_faces_from_train_dataset,person)\n",
    "        counter += 1\n",
    "    label += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae736b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_from_train_dataset          = np.array(faces_from_train_dataset)  \n",
    "# Global centering (focus on one feature, centering all samples)\n",
    "faces_centered_from_train_dataset = faces_from_train_dataset - faces_from_train_dataset.mean(axis = 0)\n",
    "#Reshape\n",
    "faces_centered_from_train_dataset = faces_centered_from_train_dataset.reshape(500 , -1)\n",
    "print(\"dataset shape:\"+str(faces_centered_from_train_dataset.shape)+\". It has N = 500 samples and dimension d = 4096\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7501c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_row, n_col = 3,3\n",
    "n_components = n_row * n_col\n",
    "image_shape = (64,64)\n",
    "\n",
    "\n",
    "def plot_gallery(title, images, n_col=n_col, n_row=n_row, cmap=plt.cm.gray):\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=n_row,\n",
    "        ncols=n_col,\n",
    "        figsize=(2.0 * n_col, 2.3 * n_row),\n",
    "        facecolor=\"white\",\n",
    "        constrained_layout=True,\n",
    "    )\n",
    "    fig.set_constrained_layout_pads(w_pad=0.01, h_pad=0.02, hspace=0, wspace=0)\n",
    "    fig.set_edgecolor(\"black\")\n",
    "    fig.suptitle(title, size=16)\n",
    "    for ax, vec in zip(axs.flat, images):\n",
    "        vmax = max(vec.max(), -vec.min())\n",
    "        im = ax.imshow(\n",
    "            vec.reshape(image_shape),\n",
    "            cmap=cmap,\n",
    "            interpolation=\"nearest\",\n",
    "            vmin=-vmax,\n",
    "            vmax=vmax,\n",
    "        )\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    fig.colorbar(im, ax=axs, orientation=\"horizontal\", shrink=0.99, aspect=40, pad=0.01)\n",
    "    plt.show()\n",
    "    \n",
    "plot_gallery(\"Faces from dataset\", faces_centered_from_train_dataset[:n_components])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd97e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Analysis(PCA) finds the directions of maximum variance in high-dimensional data \n",
    "# and projects it onto a new subspace with equal or fewer dimensions than the original one\n",
    "\n",
    "train_pca_100 = PCA(n_components = 100) #Keep the first 100\n",
    "pca_100_converted_training_data = train_pca_100.fit_transform(faces_centered_from_train_dataset)\n",
    "print(\"The data reduced from \"+str(faces_centered_from_train_dataset.shape)+\" to \"+str(pca_100_converted_training_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d1565",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pca_50 = PCA(n_components = 50)\n",
    "pca_50_converted_training_data = train_pca_50.fit_transform(faces_centered_from_train_dataset)\n",
    "print(\"The data reduced from \"+str(faces_centered_from_train_dataset.shape)+\" to \"+str(pca_50_converted_training_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7773a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pca_25 = PCA(n_components = 25)\n",
    "pca_25_converted_training_data = train_pca_25.fit_transform(faces_centered_from_train_dataset)\n",
    "print(\"The data reduced from \"+str(faces_centered_from_train_dataset.shape)+\" to \"+str(pca_25_converted_training_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58f2795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs to Agglomerative Clustering and K-Means algorithm\n",
    "inputs = [pca_100_converted_training_data,pca_50_converted_training_data,pca_25_converted_training_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef47758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining kmeans function\n",
    "def kmeans(x,k,distance_metric,no_of_iterations):\n",
    "    idx = np.random.choice(len(x), k, replace=False)\n",
    "    #Randomly choosing Centroids \n",
    "    centroids = x[idx, :] #Step 1\n",
    "     \n",
    "    #finding the distance between centroids and all the data points\n",
    "    distances = cdist(x, centroids ,distance_metric) #Step 2\n",
    "     \n",
    "    #Centroid with the minimum Distance\n",
    "    points = np.array([np.argmin(i) for i in distances]) #Step 3\n",
    "     \n",
    "    #Repeating the above steps for a defined number of iterations\n",
    "    #Step 4\n",
    "    for _ in range(no_of_iterations): \n",
    "        centroids = []\n",
    "        for idx in range(k):\n",
    "            #Updating Centroids by taking mean of Cluster it belongs to\n",
    "            if np.all(x[points == idx]) == 0:\n",
    "                temp_cent = 0\n",
    "                centroids.append(temp_cent)\n",
    "            else:\n",
    "                temp_cent = x[points==idx].mean(axis=0) \n",
    "                centroids.append(temp_cent)\n",
    " \n",
    "        centroids = np.vstack(centroids) #Updated Centroids \n",
    "         \n",
    "        distances = cdist(x, centroids , distance_metric)\n",
    "        points = np.array([np.argmin(i) for i in distances])\n",
    "         \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c380c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation of purity_score function\n",
    "def purity_score(cm , y_true, y_pred):\n",
    "    # return purity score\n",
    "    return np.sum(np.amax(cm, axis=0)) / np.sum(cm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e47855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function that calculates the true positives , false positives , true negatives and false negatives\n",
    "def calculate_TP_FP_TN_FN(cm):\n",
    "    FP = cm.sum(axis = 0) - np.diag(cm) #False Positives\n",
    "    FN = cm.sum(axis = 1) - np.diag(cm) #False Negatives\n",
    "    TP = np.diag(cm) #True Positives\n",
    "    TN = cm.sum() - (FP + FN + TP) #True Negatives\n",
    "    \n",
    "    total_TP = sum(TP) #Total True Positives\n",
    "    total_TN = sum(TN) #Total True Negatives\n",
    "    total_FP = sum(FP) #Total False Positives\n",
    "    total_FN = sum(FN) #Total False Negatives\n",
    "    \n",
    "    return total_TP , total_FP , total_TN , total_FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551017d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_precision_recall_F_measure(TP,FP,TN,FN):\n",
    "    F_measure , precision , recall , accuracy = 0 , 0 , 0 , 0 \n",
    "    a = 1\n",
    "    precision  = TP / (TP + FP) #Calculation of precision score\n",
    "    recall     = TP / (TP + FN) #Calculation of recall score\n",
    "    F_measure  = (1 + a) / ( (1 / precision) + (a / recall) ) #Caclculation of F_measure score\n",
    "    accuracy   = (TP + TN) / (TP + TN + FP + FN) #Calculation of accuracy\n",
    "    return accuracy , precision , recall , F_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712cb62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of K-Means with Euclidean/Cosine purity_scores and F_measures\n",
    "\n",
    "for dm in distance_metrics:\n",
    "    for inp in inputs:\n",
    "        y_pred            = kmeans(inp , 10 , dm , 1000)           #The predictions of K-Means Algorithm\n",
    "        cm                = confusion_matrix(y_true , y_pred)      #Calculate the confusion matrix\n",
    "        TP , FP , TN , FN = calculate_TP_FP_TN_FN(cm)              #Calculate TP , FP , TN , FN\n",
    "        accuracy , precision , recall  , F_measure = calculate_accuracy_precision_recall_F_measure(TP , FP , TN , FN) #Calculation of total F measure\n",
    "        purity            = purity_score(cm , y_true , y_pred)     #Calculate purity score\n",
    "        list_F_measures.append(F_measure)\n",
    "        list_purity_scores.append(purity)\n",
    "        list_precision_scores.append(precision)\n",
    "        list_recall_scores.append(recall)\n",
    "        list_accuracy_scores.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ecb8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_precision_scores= [list_precision_scores[0], list_precision_scores[1]  , list_precision_scores[2]]\n",
    "euclidean_recall_scores   = [list_recall_scores[0]   , list_recall_scores[1]     , list_recall_scores[2]]\n",
    "euclidean_F_measures      = [list_F_measures[0]      , list_F_measures[1]        , list_F_measures[2]]\n",
    "euclidean_purity_scores   = [list_purity_scores[0]   , list_purity_scores[1]     , list_purity_scores[2]]\n",
    "euclidean_accuracy_scores = [list_accuracy_scores[0] , list_accuracy_scores[1]   , list_accuracy_scores[2]]\n",
    "\n",
    "cosine_precision_scores   = [list_precision_scores[3] , list_precision_scores[4] , list_precision_scores[5]] \n",
    "cosine_recall_scores      = [list_recall_scores[3]    , list_recall_scores[4]    , list_recall_scores[5]]\n",
    "cosine_F_measures         = [list_F_measures[3]       , list_F_measures[4]       , list_F_measures[5]]\n",
    "cosine_purity_scores      = [list_purity_scores[3]    , list_purity_scores[4]    , list_purity_scores[5]]\n",
    "cosine_accuracy_scores    = [list_accuracy_scores[3]  , list_accuracy_scores[4]  , list_accuracy_scores[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4508b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"K-means with Euclidean distance metric\")\n",
    "print(\"dimension of data:\"+str(inputs[0].shape)+\"\\naccuracy:\"+str(euclidean_accuracy_scores[0])+\"\\nprecision:\"+str(euclidean_precision_scores[0])+\"\\nrecall:\"+str(euclidean_recall_scores[0])+\"\\nF-measure:\"+str(euclidean_F_measures[0])+\"\\npurity:\"+str(euclidean_purity_scores[0]))\n",
    "print(\"\\ndimension of data:\"+str(inputs[1].shape)+\"\\naccuracy:\"+str(euclidean_accuracy_scores[1])+\"\\nprecision:\"+str(euclidean_precision_scores[1])+\"\\nrecall:\"+str(euclidean_recall_scores[1])+\"\\nF-measure:\"+str(euclidean_F_measures[1])+\"\\npurity:\"+str(euclidean_purity_scores[1]))\n",
    "print(\"\\ndimension of data:\"+str(inputs[2].shape)+\"\\naccuracy:\"+str(euclidean_accuracy_scores[2])+\"\\nprecision:\"+str(euclidean_precision_scores[2])+\"\\nrecall:\"+str(euclidean_recall_scores[2])+\"\\nF-measure:\"+str(euclidean_F_measures[2])+\"\\npurity:\"+str(euclidean_purity_scores[2]))\n",
    "print(\"\\n\\nK-means with Cosine distance metric\")\n",
    "print(\"dimension of data:\"+str(inputs[0].shape)+\"\\naccuracy:\"+str(cosine_accuracy_scores[0])+\"\\nprecision:\"+str(cosine_precision_scores[0])+\"\\nrecall:\"+str(cosine_recall_scores[0])+\"\\nF-measure:\"+str(cosine_F_measures[0])+\"\\npurity:\"+str(cosine_purity_scores[0]))\n",
    "print(\"\\ndimension of data:\"+str(inputs[1].shape)+\"\\naccuracy:\"+str(cosine_accuracy_scores[1])+\"\\nprecision:\"+str(cosine_precision_scores[1])+\"\\nrecall:\"+str(cosine_recall_scores[1])+\"\\nF-measure:\"+str(cosine_F_measures[1])+\"\\npurity:\"+str(cosine_purity_scores[1]))\n",
    "print(\"\\ndimension of data:\"+str(inputs[2].shape)+\"\\naccuracy:\"+str(cosine_accuracy_scores[2])+\"\\nprecision:\"+str(cosine_precision_scores[2])+\"\\nrecall:\"+str(cosine_recall_scores[2])+\"\\nF-measure:\"+str(cosine_F_measures[2])+\"\\npurity:\"+str(cosine_purity_scores[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f4f92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo_clustering = AgglomerativeClustering(n_clusters = 10 , affinity = 'euclidean' , linkage = 'ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c71f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agglomerative Clustering\n",
    "#Because linkage = 'ward' , only affinity = 'euclidean' is accepted.\n",
    "#Affinity is the metric used to compute the linkage.\n",
    "\n",
    "for inp in inputs:\n",
    "    y_pred            = agglo_clustering.fit_predict(inp)\n",
    "    cm                = confusion_matrix(y_true , y_pred)      #Calculate the confusion matrix\n",
    "    TP , FP , TN , FN = calculate_TP_FP_TN_FN(cm)              #Calculate TP , FP , TN , FN\n",
    "    accuracy , precision , recall  , F_measure = calculate_accuracy_precision_recall_F_measure(TP , FP , TN , FN) \n",
    "    purity            = purity_score(cm , y_true , y_pred)     #Calculate purity score\n",
    "    agglo_clust_accuracy_scores.append(accuracy)\n",
    "    agglo_clust_precision.append(precision)\n",
    "    agglo_clust_recall.append(recall)\n",
    "    agglo_clust_F_measures.append(F_measure)\n",
    "    agglo_clust_purity_scores.append(purity)\n",
    "    print(\"\\n\")\n",
    "    print(\"dimension of data:\"+str(inp.shape))\n",
    "    print(\"The number of clusters found by the algorithm: \"+str(agglo_clustering.n_clusters_))    \n",
    "    print(\"Number of features seen during fit: \"+str(agglo_clustering.n_features_in_)) \n",
    "    print(\"Number of leaves in the hierarchical tree: \"+str(agglo_clustering.n_leaves_))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab30483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Agglomerative Clustering\")\n",
    "print(\"\\ndimension of data:\"+str(inputs[0].shape)+\"\\naccuracy:\"+str(agglo_clust_accuracy_scores[0])+\"\\nprecision:\"+str(agglo_clust_precision[0])+\"\\nrecall:\"+str(agglo_clust_recall[0])+\"\\nF-measure:\"+str(agglo_clust_F_measures[0])+\"\\npurity:\"+str(agglo_clust_purity_scores[0]))\n",
    "print(\"\\ndimension of data:\"+str(inputs[1].shape)+\"\\naccuracy:\"+str(agglo_clust_accuracy_scores[1])+\"\\nprecision:\"+str(agglo_clust_precision[1])+\"\\nrecall:\"+str(agglo_clust_recall[1])+\"\\nF-measure:\"+str(agglo_clust_F_measures[1])+\"\\npurity:\"+str(agglo_clust_purity_scores[1]))\n",
    "print(\"\\ndimension of data:\"+str(inputs[2].shape)+\"\\naccuracy:\"+str(agglo_clust_accuracy_scores[2])+\"\\nprecision:\"+str(agglo_clust_precision[2])+\"\\nrecall:\"+str(agglo_clust_recall[2])+\"\\nF-measure:\"+str(agglo_clust_F_measures[2])+\"\\npurity:\"+str(agglo_clust_purity_scores[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f821ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = faces_centered_from_train_dataset\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de773b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation of AutoEncoder with architecture d - d/4 -M -d/4 -d, where d = 4096 and M = [100,50,25]\n",
    "\n",
    "#Input to encoder\n",
    "encoder_input  = Input(shape = (4096,))\n",
    "\n",
    "#Encoder\n",
    "encoder_output = Dense(1024 , activation= 'relu')(encoder_input)\n",
    "latent_vector  = Dense(100 , activation = 'relu')(encoder_output)\n",
    "\n",
    "#Decoder\n",
    "decoder_input  = Dense(1024 , activation= 'relu')(latent_vector)\n",
    "decoder_output = Dense(4096 , activation= 'relu')(decoder_input)\n",
    "\n",
    "#Defining the model.Group layers into an object with training and inference features\n",
    "autoencoder    = Model(inputs = encoder_input , outputs = decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47912b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the AutoEncoder\n",
    "autoencoder.compile(optimizer = 'adam' , loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f59067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the train_data to the AutoEncoder\n",
    "autoencoder.fit(\n",
    "                x_train , x_train,\n",
    "                epochs = 10,\n",
    "                batch_size = 10,\n",
    "                shuffle = True,\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
